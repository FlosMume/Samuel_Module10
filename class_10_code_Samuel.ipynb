{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a RAG Agent with LangGraph: Complete Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more detail Langgraph Agent learning, you can check this repo: https://github.com/ScottLL/langgraph_lib\n",
    "\n",
    "## 1. Introduction to RAG Agents\n",
    "\n",
    "### What is a RAG Agent?\n",
    "\n",
    "A **RAG (Retrieval-Augmented Generation) Agent** combines the power of Large Language Models (LLMs) with external knowledge retrieval capabilities. Unlike standalone LLMs that are limited to their training data, RAG agents can:\n",
    "\n",
    "- **Access up-to-date information** from external documents\n",
    "- **Perform multi-step reasoning** with retrieved context\n",
    "- **Maintain conversation state** across interactions\n",
    "- **Use specialized tools** for document retrieval\n",
    "\n",
    "### Key Components We'll Build:\n",
    "\n",
    "1. **Document Processor**: Loads and chunks PDF documents\n",
    "2. **Vector Store**: Creates searchable embeddings of document chunks\n",
    "3. **Retrieval Tool**: Searches for relevant information\n",
    "4. **LLM Agent**: Reasons with retrieved information\n",
    "5. **Graph Orchestrator**: Manages the agent workflow\n",
    "\n",
    "### Architecture Overview:\n",
    "\n",
    "```\n",
    "User Query ‚Üí LLM Agent ‚Üí Retrieval Tool ‚Üí Vector Store ‚Üí PDF Documents\n",
    "     ‚Üë                        ‚Üì\n",
    "     ‚îî‚îÄ‚îÄ Final Response ‚Üê LLM Agent ‚Üê Retrieved Context\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Start Anaconda to enter the working directory:\n",
    "cd C:\\Users\\ch939\\Downloads\\LLMBootCampCodes\\Week10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Open VS Code terminal\n",
    "code ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Create virtual environment\n",
    "conda create -n langchain_venv python=3.10.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Activate the virtual environment\n",
    "conda activate langchain_venv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Upgrade pip\n",
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Install PyTorch (GPU build for CUDA 12.8)\n",
    "Since my RTX 4070 SUPER + CUDA 12.8 is very recent, install via PyTorch‚Äôs official channel:\n",
    "\n",
    "However, pytorch-cuda=12.8 is not a valid package name or version in the PyTorch or NVIDIA conda channels.\n",
    "\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will install:\n",
    "* PyTorch (GPU-enabled)\n",
    "* CUDA 12.8 runtime (no need to match driver manually ‚Äî it uses your system driver)\n",
    "* cuDNN (already included in package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 Install Jupyter + extras\n",
    "conda install jupyter \n",
    "\n",
    "\n",
    "conda install -c conda-forge numpy scipy pandas  \n",
    "\n",
    "pip install langchain langchain-openai langchain-community langgraph chromadb pypdf python-dotenv langchain_chroma\n",
    "\n",
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from operator import add as add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Load environment variables (make sure you have OPENAI_API_KEY in your .env file)\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° What's happening here?**\n",
    "- **LangChain**: Framework for building LLM applications\n",
    "- **LangGraph**: Creates state-based agent workflows\n",
    "- **ChromaDB**: Vector database for storing embeddings\n",
    "- **OpenAI**: LLM and embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Initialization \n",
    "\n",
    "Let's set up our LLM and embedding models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ LLM initialized: GPT-4o\n",
      "üîç Embeddings initialized: text-embedding-3-small\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Language Model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\", \n",
    "    temperature=0  # Low temperature for more deterministic responses\n",
    ")\n",
    "\n",
    "# Initialize the Embedding Model\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",  # Efficient embedding model\n",
    ")\n",
    "\n",
    "print(\"ü§ñ LLM initialized: GPT-4o\")\n",
    "print(\"üîç Embeddings initialized: text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîç Key Parameters:**\n",
    "- **Temperature = 0**: Makes responses more deterministic and factual\n",
    "- **text-embedding-3-small**: Cost-effective embedding model for document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document Loading and Processing\n",
    "\n",
    "Now let's load and process our PDF document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Found PDF: Stock_Market_Performance_2024.pdf\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your PDF document\n",
    "pdf_path = \"Stock_Market_Performance_2024.pdf\"\n",
    "\n",
    "# Safety check: Verify PDF exists\n",
    "if not os.path.exists(pdf_path):\n",
    "    raise FileNotFoundError(f\"‚ùå PDF file not found: {pdf_path}\")\n",
    "    \n",
    "print(f\"üìÑ Found PDF: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF loaded successfully!\n",
      "üìä Document contains 9 pages\n",
      "üìù First page preview: Stock Market Performance in 2024\n",
      "U.S. Market Overview\n",
      "The year 2024 was a remarkably strong one for equities, with the U.S. stock market extending the\n",
      "robust gains seen in the prior year. The benchmar...\n"
     ]
    }
   ],
   "source": [
    "# Load the PDF document\n",
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "try:\n",
    "    pages = pdf_loader.load()\n",
    "    print(f\"‚úÖ PDF loaded successfully!\")\n",
    "    print(f\"üìä Document contains {len(pages)} pages\")\n",
    "    \n",
    "    # Preview first page content (first 200 characters)\n",
    "    if pages:\n",
    "        print(f\"üìù First page preview: {pages[0].page_content[:200]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading PDF: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîÑ What's happening?**\n",
    "- **PyPDFLoader**: Extracts text from each page of the PDF\n",
    "- **Error handling**: Ensures robust document loading\n",
    "- **Content preview**: Shows what was extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Chunking \n",
    "\n",
    "Large documents need to be split into smaller, manageable chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Original pages: 9\n",
      "üîç Total chunks created: 24\n",
      "üìè Average chunk size: 868 characters\n",
      "\n",
      "üìù Sample chunk:\n",
      "Stock Market Performance in 2024\n",
      "U.S. Market Overview\n",
      "The year 2024 was a remarkably strong one for equities, with the U.S. stock market extending the\n",
      "robust gains seen in the prior year. The benchmark S&P 500 index delivered roughly a 25% total\n",
      "return for 2024 (around +23% in price terms)\n",
      ". This ma...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Maximum characters per chunk\n",
    "    chunk_overlap=200     # Overlap between chunks to maintain context\n",
    ")\n",
    "\n",
    "# Split the document into chunks\n",
    "pages_split = text_splitter.split_documents(pages)\n",
    "\n",
    "print(f\"üìÑ Original pages: {len(pages)}\")\n",
    "print(f\"üîç Total chunks created: {len(pages_split)}\")\n",
    "print(f\"üìè Average chunk size: {sum(len(chunk.page_content) for chunk in pages_split) // len(pages_split)} characters\")\n",
    "\n",
    "# Preview a sample chunk\n",
    "if pages_split:\n",
    "    print(f\"\\nüìù Sample chunk:\\n{pages_split[0].page_content[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Chunking Strategy:**\n",
    "- **Chunk size (1000)**: Balance between context and retrieval precision\n",
    "- **Overlap (200)**: Prevents information loss at chunk boundaries\n",
    "- **Recursive splitting**: Maintains semantic coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vector Store Creation\n",
    "\n",
    "Create a ChromaDB vector store to enable semantic search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Created directory: ./chroma_db\n",
      "‚úÖ ChromaDB vector store created successfully!\n",
      "üìä Indexed 24 document chunks\n"
     ]
    }
   ],
   "source": [
    "# Set up ChromaDB configuration\n",
    "persist_directory = \"./chroma_db\"  # Local directory for vector store\n",
    "collection_name = \"stock_market\"   # Collection name for our documents\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(persist_directory):\n",
    "    os.makedirs(persist_directory)\n",
    "    print(f\"üìÅ Created directory: {persist_directory}\")\n",
    "\n",
    "try:\n",
    "    # Create the ChromaDB vector store\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=pages_split,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(f\"‚úÖ ChromaDB vector store created successfully!\")\n",
    "    print(f\"üìä Indexed {len(pages_split)} document chunks\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error setting up ChromaDB: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üíæ Vector Store Benefits:**\n",
    "- **Semantic search**: Find similar content, not just keyword matches\n",
    "- **Persistent storage**: Database saves to disk for reuse\n",
    "- **Efficient retrieval**: Fast similarity search across large documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Building the Retrieval Tool\n",
    "\n",
    "Create a retriever and wrap it in a tool that the agent can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retriever configured to return top 5 similar chunks\n"
     ]
    }
   ],
   "source": [
    "# Create the retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # Return top 5 most similar chunks\n",
    ")\n",
    "\n",
    "print(f\"üîç Retriever configured to return top 5 similar chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Retrieval tool created successfully!\n",
      "üìã Tool description: This tool searches and returns information from the Stock Market Performance 2024 document.\n",
      "Use this tool when you need to find specific information about stock market data, trends, or analysis.\n"
     ]
    }
   ],
   "source": [
    "# Define the retrieval tool using LangChain's @tool decorator\n",
    "@tool\n",
    "def retriever_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    This tool searches and returns information from the Stock Market Performance 2024 document.\n",
    "    Use this tool when you need to find specific information about stock market data, trends, or analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform the similarity search\n",
    "    docs = retriever.invoke(query)\n",
    "    \n",
    "    # Handle case where no documents are found\n",
    "    if not docs:\n",
    "        return \"I found no relevant information in the Stock Market Performance 2024 document.\"\n",
    "    \n",
    "    # Format the retrieved documents\n",
    "    results = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        results.append(f\"Document {i+1}:\\n{doc.page_content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(results)\n",
    "\n",
    "# Test the retrieval tool\n",
    "print(\"üõ†Ô∏è Retrieval tool created successfully!\")\n",
    "print(\"üìã Tool description:\", retriever_tool.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîß Tool Features:**\n",
    "- **Similarity search**: Finds semantically relevant content\n",
    "- **Formatted output**: Returns structured, numbered results\n",
    "- **Error handling**: Graceful handling of empty results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Agent State and Architecture\n",
    "\n",
    "Define the agent's state and workflow structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Agent state schema defined\n"
     ]
    }
   ],
   "source": [
    "# Define the agent's state schema\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    The state of our agent conversation.\n",
    "    Messages are accumulated using the add_messages function.\n",
    "    \"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "print(\"üìã Agent state schema defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Available tools: ['retriever_tool']\n",
      "ü§ñ LLM bound with 1 tools\n"
     ]
    }
   ],
   "source": [
    "# Create tools list and bind to LLM\n",
    "tools = [retriever_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Create tools dictionary for easy lookup\n",
    "tools_dict = {tool.name: tool for tool in tools}\n",
    "\n",
    "print(f\"üîß Available tools: {list(tools_dict.keys())}\")\n",
    "print(f\"ü§ñ LLM bound with {len(tools)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üèóÔ∏è Architecture Components:**\n",
    "- **AgentState**: Maintains conversation history\n",
    "- **Tool binding**: Allows LLM to call our retrieval function\n",
    "- **Tools dictionary**: Enables dynamic tool execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Agent Functions \n",
    "\n",
    "Define the core agent functions for reasoning and tool execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Continuation logic defined\n"
     ]
    }
   ],
   "source": [
    "def should_continue(state: AgentState) -> bool:\n",
    "    \"\"\"\n",
    "    Determines if the agent should continue with tool calls.\n",
    "    Returns True if the last message contains tool calls, False otherwise.\n",
    "    \"\"\"\n",
    "    last_message = state['messages'][-1]\n",
    "    has_tool_calls = hasattr(last_message, 'tool_calls') and len(last_message.tool_calls) > 0\n",
    "    \n",
    "    print(f\"ü§î Should continue? {has_tool_calls}\")\n",
    "    return has_tool_calls\n",
    "\n",
    "print(\"‚úÖ Continuation logic defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìú System prompt configured\n"
     ]
    }
   ],
   "source": [
    "# System prompt for the agent\n",
    "system_prompt = \"\"\"\n",
    "You are an intelligent AI assistant specialized in analyzing Stock Market Performance data from 2024.\n",
    "\n",
    "Your capabilities:\n",
    "- Use the retriever tool to search through the Stock Market Performance 2024 document\n",
    "- Provide accurate, data-driven answers based on the retrieved information\n",
    "- Make multiple tool calls if needed to gather comprehensive information\n",
    "- Always cite specific parts of the documents you reference\n",
    "\n",
    "Instructions:\n",
    "- When answering questions, first search for relevant information using the retriever tool\n",
    "- If you need additional context, make follow-up searches with different keywords\n",
    "- Always provide specific citations from the documents\n",
    "- Be clear about the source of your information\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìú System prompt configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM function defined\n"
     ]
    }
   ],
   "source": [
    "def call_llm(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    The main reasoning function that calls the LLM with current state.\n",
    "    \"\"\"\n",
    "    messages = list(state['messages'])\n",
    "    # Add system prompt to the beginning\n",
    "    messages = [SystemMessage(content=system_prompt)] + messages\n",
    "    \n",
    "    print(\"üß† Calling LLM for reasoning...\")\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    print(f\"üí¨ LLM response type: {type(response).__name__}\")\n",
    "    if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "        print(f\"üîß LLM wants to use {len(response.tool_calls)} tools\")\n",
    "    \n",
    "    return {'messages': [response]}\n",
    "\n",
    "print(\"‚úÖ LLM function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tool execution function defined\n"
     ]
    }
   ],
   "source": [
    "def take_action(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Executes tool calls from the LLM's response.\n",
    "    \"\"\"\n",
    "    last_message = state['messages'][-1]\n",
    "    tool_calls = last_message.tool_calls\n",
    "    \n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call['name']\n",
    "        tool_args = tool_call['args']\n",
    "        \n",
    "        print(f\"üîß Executing tool: {tool_name}\")\n",
    "        print(f\"üìù Query: {tool_args.get('query', 'No query provided')}\")\n",
    "        \n",
    "        if tool_name not in tools_dict:\n",
    "            print(f\"‚ùå Tool '{tool_name}' not found!\")\n",
    "            result = f\"Error: Tool '{tool_name}' does not exist.\"\n",
    "        else:\n",
    "            try:\n",
    "                result = tools_dict[tool_name].invoke(tool_args.get('query', ''))\n",
    "                print(f\"‚úÖ Tool executed successfully. Result length: {len(str(result))} characters\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Tool execution error: {e}\")\n",
    "                result = f\"Error executing tool: {e}\"\n",
    "        \n",
    "        # Create tool message\n",
    "        tool_message = ToolMessage(\n",
    "            tool_call_id=tool_call['id'], \n",
    "            name=tool_name, \n",
    "            content=str(result)\n",
    "        )\n",
    "        results.append(tool_message)\n",
    "\n",
    "    print(f\"üîÑ Returning {len(results)} tool results to LLM\")\n",
    "    return {'messages': results}\n",
    "\n",
    "print(\"‚úÖ Tool execution function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîÑ Agent Workflow:**\n",
    "1. **call_llm**: LLM reasons and decides on actions\n",
    "2. **should_continue**: Checks if tools need to be called  \n",
    "3. **take_action**: Executes the chosen tools\n",
    "4. **Loop back**: Returns to LLM with tool results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Graph Construction\n",
    "\n",
    "Build the LangGraph workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Graph nodes added: llm, retriever_agent\n"
     ]
    }
   ],
   "source": [
    "# Create the state graph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.add_node(\"llm\", call_llm)\n",
    "graph.add_node(\"retriever_agent\", take_action)\n",
    "\n",
    "print(\"üìä Graph nodes added: llm, retriever_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Graph edges and entry point configured\n"
     ]
    }
   ],
   "source": [
    "# Add conditional edges\n",
    "graph.add_conditional_edges(\n",
    "    \"llm\",                    # Start from LLM\n",
    "    should_continue,          # Decision function\n",
    "    {True: \"retriever_agent\", False: END}  # If True -> tools, if False -> end\n",
    ")\n",
    "\n",
    "# Add edge from tools back to LLM\n",
    "graph.add_edge(\"retriever_agent\", \"llm\")\n",
    "\n",
    "# Set the entry point\n",
    "graph.set_entry_point(\"llm\")\n",
    "\n",
    "print(\"üîó Graph edges and entry point configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG Agent compiled successfully!\n",
      "üéØ Agent is ready to handle queries!\n"
     ]
    }
   ],
   "source": [
    "# Compile the graph\n",
    "rag_agent = graph.compile()\n",
    "\n",
    "print(\"‚úÖ RAG Agent compiled successfully!\")\n",
    "print(\"üéØ Agent is ready to handle queries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Graph Flow:**\n",
    "```\n",
    "Start ‚Üí LLM ‚Üí Decision ‚Üí [Tools] ‚Üí LLM ‚Üí End\n",
    "                ‚Üì         ‚Üë\n",
    "                End   Results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Testing the Agent\n",
    "\n",
    "Let's test our RAG agent with a sample query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Testing Query: 'What were the key trends in the stock market during 2024?'\n",
      "==================================================\n",
      "üß† Calling LLM for reasoning...\n",
      "üí¨ LLM response type: AIMessage\n",
      "üîß LLM wants to use 1 tools\n",
      "ü§î Should continue? True\n",
      "üîß Executing tool: retriever_tool\n",
      "üìù Query: key trends in stock market 2024\n",
      "‚úÖ Tool executed successfully. Result length: 4664 characters\n",
      "üîÑ Returning 1 tool results to LLM\n",
      "üß† Calling LLM for reasoning...\n",
      "üí¨ LLM response type: AIMessage\n",
      "ü§î Should continue? False\n",
      "\n",
      "ü§ñ Agent Response:\n",
      "The key trends in the stock market during 2024 were characterized by a strong performance driven predominantly by the technology sector. Here are the main highlights:\n",
      "\n",
      "1. **Tech-Dominated Rally**: 2024 was marked by a tech-dominated rally, with significant wealth gains concentrated in the technology sector. This was driven by the adoption of next-generation technologies such as artificial intelligence, cloud computing, and quantum technology. The market saw substantial performances from mega-cap tech companies like Apple, Alphabet, and Meta, as well as newer companies riding the wave of tech innovation (Document 1, Document 2).\n",
      "\n",
      "2. **S&P 500 and Nasdaq Performance**: The S&P 500 index delivered a roughly 25% total return for the year, marking the second consecutive year of over 20% returns. The tech-heavy Nasdaq Composite outpaced the broader market with a nearly 29% jump. However, smaller-cap stocks had more modest performance, highlighting the uneven distribution of the rally across the market (Document 3).\n",
      "\n",
      "3. **\"Magnificent 7\" Companies**: A group of seven powerhouse companies, often referred to as the \"Magnificent 7\" (Apple, Microsoft, Alphabet, Amazon, Meta, Nvidia, and Tesla), collectively surged by approximately 64-67% on average. These companies contributed disproportionately to the S&P 500's gains, accounting for over half of the index's return for the year (Document 5).\n",
      "\n",
      "4. **Valuation Concerns**: The surge in stock prices led to significantly increased valuations, with many leading stocks trading at rich multiples by year-end. This exuberance created some caution among investors about potential corrections, given the rapid climb in stock prices (Document 2).\n",
      "\n",
      "Overall, 2024 was a year of exceptional stock market performance, underpinned by real improvements in corporate fortunes and a robust appetite for risk, particularly in the technology sector.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def test_agent_query(question: str):\n",
    "    \"\"\"\n",
    "    Test function to demonstrate agent capabilities\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Testing Query: '{question}'\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create human message\n",
    "    messages = [HumanMessage(content=question)]\n",
    "    \n",
    "    # Run the agent\n",
    "    result = rag_agent.invoke({\"messages\": messages})\n",
    "    \n",
    "    # Print the final response\n",
    "    final_response = result['messages'][-1].content\n",
    "    print(f\"\\nü§ñ Agent Response:\\n{final_response}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test with a sample question\n",
    "sample_question = \"What were the key trends in the stock market during 2024?\"\n",
    "test_result = test_agent_query(sample_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üß™ What to expect:**\n",
    "- The agent will search the document for relevant information\n",
    "- It will provide a comprehensive answer with citations\n",
    "- You'll see the tool execution logs in real-time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Interactive Agent Interface \n",
    "\n",
    "Create an interactive interface to chat with your agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5415e43e0f474856889668aa50a1d1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ü§ñ RAG Agent - Stock Market Assistant</h3>'), Textarea(value='', description='Qu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    \n",
    "    def create_interactive_widget():\n",
    "        \"\"\"\n",
    "        Creates an interactive widget interface for the RAG agent\n",
    "        Requires: pip install ipywidgets\n",
    "        \"\"\"\n",
    "        # Create widgets\n",
    "        question_input = widgets.Textarea(\n",
    "            placeholder=\"Enter your question about stock market performance...\",\n",
    "            description=\"Question:\",\n",
    "            layout=widgets.Layout(width='70%', height='80px')\n",
    "        )\n",
    "        \n",
    "        ask_button = widgets.Button(\n",
    "            description=\"Ask Agent\",\n",
    "            button_style='primary',\n",
    "            icon='search'\n",
    "        )\n",
    "        \n",
    "        output_area = widgets.Output()\n",
    "        \n",
    "        def on_ask_button_click(b):\n",
    "            with output_area:\n",
    "                clear_output(wait=True)\n",
    "                if question_input.value.strip():\n",
    "                    print(f\"üîç Question: {question_input.value}\")\n",
    "                    print(\"=\" * 50)\n",
    "                    print(\"üîÑ Processing...\")\n",
    "                    \n",
    "                    try:\n",
    "                        messages = [HumanMessage(content=question_input.value)]\n",
    "                        result = rag_agent.invoke({\"messages\": messages})\n",
    "                        \n",
    "                        print(\"\\nü§ñ AGENT RESPONSE:\")\n",
    "                        print(\"-\" * 30)\n",
    "                        print(result['messages'][-1].content)\n",
    "                        print(\"=\" * 50)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Error: {e}\")\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è Please enter a question!\")\n",
    "        \n",
    "        ask_button.on_click(on_ask_button_click)\n",
    "        \n",
    "        # Display the interface\n",
    "        display(widgets.VBox([\n",
    "            widgets.HTML(\"<h3>ü§ñ RAG Agent - Stock Market Assistant</h3>\"),\n",
    "            question_input,\n",
    "            ask_button,\n",
    "            output_area\n",
    "        ]))\n",
    "    \n",
    "    # Uncomment to create the widget interface:\n",
    "    create_interactive_widget()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"ipywidgets not available. Use the simple ask_agent() function instead.\")\n",
    "    \n",
    "# Example question: What were the key stock market trends in 2024? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Usage Tips:**\n",
    "\n",
    "- Ask specific questions about stock market data\n",
    "- Request comparisons between different time periods\n",
    "- Ask for trends, analysis, or specific metrics\n",
    "- The agent will search and cite relevant document sections\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Advanced Features\n",
    "**Multiple Document Support**\n",
    "To extend this agent for multiple documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded: Stock_Market_Performance_2024.pdf (9 pages)\n",
      "‚úÖ Loaded: U.S._Economic_Outlook.pdf (29 pages)\n"
     ]
    }
   ],
   "source": [
    "def load_multiple_documents(pdf_paths: list):\n",
    "    \"\"\"\n",
    "    Example function to load multiple PDF documents\n",
    "    \"\"\"\n",
    "    all_pages = []\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        if os.path.exists(pdf_path):\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            pages = loader.load()\n",
    "            all_pages.extend(pages)\n",
    "            print(f\"‚úÖ Loaded: {pdf_path} ({len(pages)} pages)\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è File not found: {pdf_path}\")\n",
    "    \n",
    "    return all_pages\n",
    "\n",
    "# Example usage (uncomment and modify paths as needed):\n",
    "document_paths = [\n",
    "    \"Stock_Market_Performance_2024.pdf\",\n",
    "    \"U.S._Economic_Outlook.pdf\"\n",
    "]\n",
    "all_documents = load_multiple_documents(document_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enhanced Search Strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_retriever(vectorstore, search_type=\"mmr\"):\n",
    "    \"\"\"\n",
    "    Create retriever with Maximum Marginal Relevance for diverse results\n",
    "    \"\"\"\n",
    "    return vectorstore.as_retriever(\n",
    "        search_type=search_type,  # \"mmr\" for diverse results\n",
    "        search_kwargs={\n",
    "            \"k\": 6,              # Return more results\n",
    "            \"fetch_k\": 20,       # Consider more candidates\n",
    "            \"lambda_mult\": 0.7   # Balance relevance vs diversity\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Example: Enhanced retriever (uncomment to use)\n",
    "enhanced_retriever = create_advanced_retriever(vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Key Concepts Summary\n",
    "**üéØ What We Built**\n",
    "\n",
    "- Document Processing Pipeline: PDF ‚Üí Text Chunks ‚Üí Embeddings ‚Üí Vector Store\n",
    "- Retrieval System: Semantic search for relevant information\n",
    "- Agent Architecture: LLM + Tools + State Management\n",
    "- Interactive Interface: User-friendly query system\n",
    "\n",
    "**üîë Key Components**\n",
    "| Component | Purpose | Technology |\n",
    "|-----------|---------|------------|\n",
    "| **PDF Loader** | Extract text from documents | PyPDFLoader |\n",
    "| **Text Splitter** | Create manageable chunks | RecursiveCharacterTextSplitter |\n",
    "| **Embeddings** | Convert text to vectors | OpenAI text-embedding-3-small |\n",
    "| **Vector Store** | Store and search embeddings | ChromaDB |\n",
    "| **LLM** | Reasoning and response generation | GPT-4o |\n",
    "| **Agent Framework** | Orchestrate workflow | LangGraph |\n",
    "\n",
    "**üöÄ Capabilities Achieved**\n",
    "\n",
    "- ‚úÖ Accurate Information Retrieval: Finds relevant document sections\n",
    "- ‚úÖ Contextual Understanding: Maintains conversation context\n",
    "- ‚úÖ Multi-step Reasoning: Can make multiple searches if needed\n",
    "- ‚úÖ Source Citation: References specific document parts\n",
    "- ‚úÖ Interactive Interface: User-friendly question-answering\n",
    "\n",
    "**üîÆ Next Steps**\n",
    "\n",
    "- Add More Tools: Web search, calculator, database queries, voice agent\n",
    "- Improve Chunking: Experiment with different strategies\n",
    "- Multi-modal Support: Add image and table processing\n",
    "- Evaluation Metrics: Implement retrieval and response quality metrics\n",
    "- Production Deployment: Add error handling, logging, and monitoring\n",
    "\n",
    "**üìö Further Learning**\n",
    "\n",
    "- LangChain Documentation: langchain.com\n",
    "- LangGraph Tutorials: langgraph.com\n",
    "- RAG Best Practices: Advanced chunking and retrieval strategies\n",
    "- Agent Design Patterns: Multi-agent systems and tool composition\n",
    "\n",
    "\n",
    "üéâ Congratulations! You've successfully built a complete RAG agent that can intelligently search through documents and provide informed responses. This foundation can be extended to handle multiple documents, different file types, and more sophisticated reasoning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
